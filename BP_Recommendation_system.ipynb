{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blistt/bp-recommender/blob/Romasa/BP_Recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yhvxGLihuQYJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "path = 'data/'\n",
        "baseline = pd.read_csv(path + 'baseline.csv')\n",
        "augmented_k = pd.read_csv(path + 'augmented_k.csv')\n",
        "augmented_inter = pd.read_csv(path + 'augmented_inter.csv')\n",
        "augmented_intra = pd.read_csv(path + 'augmented_intra.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bp_predictor import BloodPresurePredictor\n",
        "from utils import log_exp\n",
        "from utils import data_split\n",
        "\n",
        "def experiment(dataset, model, ntrees, N, key, target, log_path='', bootstrap=False, \n",
        "               bootstrap_size=0.8, aug='None'):\n",
        "    # Split dataset into train and test sets of features and labels\n",
        "    (x_train, y_train), (x_test, y_test) = data_split(dataset, y_columns=target, key_cols=key)\n",
        "    x_train = x_train.drop(key, axis=1)\n",
        "    x_test = x_test.drop(key, axis=1)\n",
        "\n",
        "    # First run with all features (either bootstrapped or not)\n",
        "    bp_predictor = BloodPresurePredictor(model, ntrees)\n",
        "    bp_predictor.fit(x_train, y_train, bootstrap, bootstrap_size)\n",
        "    # Evaluate the model\n",
        "    bp_predictor.evaluate(x_test, y_test)\n",
        "    \n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=False, bootstrap=bootstrap, test_size=x_test.shape)     \n",
        "    \n",
        "    # Second run with top N features\n",
        "    top_n = list(bp_predictor.feature_importances.keys())[:N]        # get top N features from dict \n",
        "    x_train = x_train[top_n]                                         # select top N features\n",
        "    bp_predictor.fit(x_train[top_n], y_train)                        # predict with top N features\n",
        "    bp_predictor.evaluate(x_test[top_n], y_test)                     # evaluate with top N features\n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=True, bootstrap=bootstrap, test_size=x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bp_predictor import BloodPresurePredictor\n",
        "from utils import log_exp, get_unique_healthCodes, average_dicts\n",
        "from collections import defaultdict\n",
        "\n",
        "def personalized_experiment(dataset, model, ntrees, N, key, target, log_path='', bootstrap=False, \n",
        "               bootstrap_size=0.8, aug='None', second_run=False, save_path=None):\n",
        "    \n",
        "    # Split dataset into train and test sets of features and labels\n",
        "    (x_train, y_train), (x_test, y_test) = data_split(dataset, y_columns=target, key_cols=key)\n",
        "    x_train_keys = x_train[key]\n",
        "    x_test_keys = x_test[key]\n",
        "    x_train = x_train.drop(key, axis=1)\n",
        "    x_test = x_test.drop(key, axis=1)\n",
        "\n",
        "    # First run with all features (either bootstrapped or not)\n",
        "    bp_predictor = BloodPresurePredictor(model, ntrees)\n",
        "    bp_predictor.fit(x_train, y_train, bootstrap, bootstrap_size)\n",
        "\n",
        "    # Get all unique healthCodes\n",
        "    all_users = get_unique_healthCodes(dataset)\n",
        "\n",
        "    # Initialize lists to store metrics results\n",
        "    mae = defaultdict(list)\n",
        "    mse = defaultdict(list)\n",
        "    temp_feature_importances = []\n",
        "    # Personalize the model for each user\n",
        "    for user in all_users:\n",
        "        tr_mask = x_train_keys.iloc[:, 0] == user\n",
        "        test_mask = x_test_keys.iloc[:, 0] == user\n",
        "        x_train_user, y_train_user = x_train[tr_mask], y_train[tr_mask]\n",
        "\n",
        "        x_test_user, y_test_user = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "        # Skips if there are no samples for the user\n",
        "        if x_train_user.shape[0] < 1 or x_test_user.shape[0] < 1:\n",
        "            continue\n",
        "\n",
        "        else:\n",
        "            bp_predictor.fine_tune(x_train_user, y_train_user)  # Fit the personalized model\n",
        "            bp_predictor.evaluate(x_test_user, y_test_user, fine_tuned=True)     # Evaluate the personalized model\n",
        "            # Performs second run with top N features if specified\n",
        "            if second_run:\n",
        "                top_n = list(bp_predictor.feature_importances.keys())[:N]\n",
        "                bp_predictor.fine_tune(x_train_user[top_n], y_train_user)\n",
        "                bp_predictor.evaluate(x_test_user[top_n], y_test_user, fine_tuned=True)\n",
        "            for bp_type in target:\n",
        "                mae[bp_type].append(bp_predictor.mae[bp_type])\n",
        "                mse[bp_type].append(bp_predictor.mse[bp_type])\n",
        "            temp_feature_importances.append(bp_predictor.feature_importances)\n",
        "\n",
        "            # Saves the model for the user\n",
        "            if save_path:\n",
        "                for bp_type in target:\n",
        "                    bp_predictor.ftmodel[bp_type].save_model(f'{save_path}/{user}_{bp_type}.json')\n",
        "\n",
        "    if len(mae) == 0:\n",
        "        print('No testing samples')\n",
        "        return\n",
        "    \n",
        "    # Average metrics for all users\n",
        "    for bp_type in target:\n",
        "        bp_predictor.mae[bp_type] = sum(mae[bp_type]) / len(mae[bp_type])\n",
        "        bp_predictor.mse[bp_type] = sum(mse[bp_type]) / len(mse[bp_type])\n",
        "    bp_predictor.feature_importances = average_dicts(temp_feature_importances)\n",
        "\n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=second_run, bootstrap=bootstrap, \n",
        "            test_size=x_test.shape, personalized=True)\n",
        "   \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DygEtRF3rPGU"
      },
      "source": [
        "**Experiments with non-personalized model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASELINE - NO AUGMENTATION\n",
            "dataset size: (4, 11), model: xgb, ntrees: 60, sys_mae: 16.0,\n",
            "           dias_mae: 9.5, top_n: floors; steps; wo_calories; distance_walking; active_calories, second run: False, bootstrap: True\n",
            "dataset size: (4, 11), model: xgb, ntrees: 60, sys_mae: 15.0,\n",
            "           dias_mae: 8.75, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "K-ROLL AUGMENTATION\n",
            "dataset size: (8, 11), model: xgb, ntrees: 60, sys_mae: 9.625,\n",
            "           dias_mae: 8.375, top_n: floors; sleep_minutes; bed_time; distance_cycling; steps, second run: False, bootstrap: True\n",
            "dataset size: (8, 11), model: xgb, ntrees: 60, sys_mae: 10.0,\n",
            "           dias_mae: 6.875, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTRA AUGMENTATION\n",
            "dataset size: (31, 11), model: xgb, ntrees: 60, sys_mae: 9.742,\n",
            "           dias_mae: 6.774, top_n: awake_count; bed_time; wo_calories; active_calories; floors, second run: False, bootstrap: True\n",
            "dataset size: (31, 11), model: xgb, ntrees: 60, sys_mae: 9.194,\n",
            "           dias_mae: 7.355, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTER AUGMENTATION\n",
            "dataset size: (224, 11), model: xgb, ntrees: 60, sys_mae: 11.531,\n",
            "           dias_mae: 9.612, top_n: bed_time; wo_calories; awake_count; steps; active_calories, second run: False, bootstrap: True\n",
            "dataset size: (224, 11), model: xgb, ntrees: 60, sys_mae: 12.152,\n",
            "           dias_mae: 9.781, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "############################################# PARAMETERS #############################################\n",
        "N = 5                               # Number of most important features to display\n",
        "model = 'xgb'                       # rf or xgb (Random Forest or XGBoost)\n",
        "ntrees = 60                         # Number of trees in the forest\n",
        "double_run = False                  # Whether to use a second run with top N features or not\n",
        "bootstrap = True                    # Whether to use bootstrap samples\n",
        "bootstrap_size = 0.8                # Portion of the dataset to sample for bootstrap\n",
        "key = ['healthCode', 'date']        # Columns to use as key\n",
        "target = ['systolic', 'diastolic']  # Columns to predict\n",
        "log_path = 'exp_log.csv'            # Path of file to log experiment results\n",
        "\n",
        "\n",
        "############################################# EXPERIMENTS #############################################\n",
        "# Predicting systolic BP using baseline with non NaN values\n",
        "print('BASELINE - NO AUGMENTATION')\n",
        "dataset = baseline\n",
        "aug = 'None'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "# Predicting systolic BP using k-roll augmentation with non NaN values\n",
        "print('K-ROLL AUGMENTATION')\n",
        "dataset = augmented_k\n",
        "aug = 'K-roll'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting systolic BP using knn intra augmentation with non NaN values\n",
        "print('KNN INTRA AUGMENTATION')\n",
        "dataset = augmented_intra\n",
        "aug = 'KNN-intra'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting systolic BP using knn inter augmentation with non NaN values\n",
        "print('KNN INTER AUGMENTATION')\n",
        "dataset = augmented_inter\n",
        "aug = 'KNN-inter'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Experiments with personalized model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASELINE - NO AUGMENTATION\n",
            "No testing samples\n",
            "--------------------------------------------------------------------------------\n",
            "K-ROLL AUGMENTATION\n",
            "dataset size: (8, 11), model: xgb, ntrees: 60, sys_mae: 21.0,\n",
            "           dias_mae: 5.0, top_n: N/A, second run: False, bootstrap: False\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTRA AUGMENTATION\n",
            "dataset size: (31, 11), model: xgb, ntrees: 60, sys_mae: 4.06,\n",
            "           dias_mae: 6.033, top_n: N/A, second run: False, bootstrap: False\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTER AUGMENTATION\n",
            "dataset size: (224, 11), model: xgb, ntrees: 60, sys_mae: 10.017,\n",
            "           dias_mae: 6.468, top_n: N/A, second run: False, bootstrap: False\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "############################################# PARAMETERS #############################################\n",
        "N = 5                               # Number of most important features to display\n",
        "ntrees = 60                         # Number of trees in the forest\n",
        "second_run = False                  # Whether to use a second run with top N features or not\n",
        "bootstrap = False                   # Whether to use bootstrap samples\n",
        "bootstrap_size = 0.8                # Portion of the dataset to sample for bootstrap\n",
        "key = ['healthCode', 'date']        # Columns to use as key\n",
        "target = ['systolic', 'diastolic']  # Columns to predict\n",
        "log_path = 'exp_log.csv'            # Path of file to log experiment results\n",
        "save_path = 'model_states'          # Path to save personalized models\n",
        "\n",
        "\n",
        "############################################# EXPERIMENTS #############################################\n",
        "# Predicting BP using baseline with non NaN values\n",
        "print('BASELINE - NO AUGMENTATION')\n",
        "aug = 'None'\n",
        "dataset = baseline\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "# Predicting BP using k-roll augmentation with non NaN values\n",
        "print('K-ROLL AUGMENTATION')\n",
        "dataset = augmented_k\n",
        "aug = 'K-roll'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting BP using knn intra augmentation with non NaN values\n",
        "print('KNN INTRA AUGMENTATION')\n",
        "dataset = augmented_intra\n",
        "aug = 'KNN-intra'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting BP using knn inter augmentation with non NaN values\n",
        "print('KNN INTER AUGMENTATION')\n",
        "dataset = augmented_inter\n",
        "aug = 'KNN-inter'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  ADD HISTORICAL BP\n",
        "'''\n",
        "Here is where we list the historical BP values for each row in master_df\n",
        "'''\n",
        "\n",
        "def historical_BP(predictor, k):\n",
        "    data = predictor.copy()\n",
        "    #Sorting the data by healthCode and date\n",
        "    data.sort_values(by=['healthCode', 'date'], inplace=True)\n",
        "\n",
        "    for col in ['systolic', 'diastolic']:\n",
        "        data[col+'_'+str(k)] = data.groupby('healthCode')[col].transform(lambda x:x.ewm(span=k, adjust=True).mean())\n",
        "\n",
        "    return data\n",
        "\n",
        "historical_3 = historical_BP(baseline, 3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
