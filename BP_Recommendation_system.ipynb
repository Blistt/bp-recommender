{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blistt/bp-recommender/blob/Romasa/BP_Recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yhvxGLihuQYJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "path = 'data/'\n",
        "baseline = pd.read_csv(path + 'baseline.csv')\n",
        "augmented_k = pd.read_csv(path + 'augmented_k.csv')\n",
        "augmented_inter = pd.read_csv(path + 'augmented_inter.csv')\n",
        "augmented_intra = pd.read_csv(path + 'augmented_intra.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bp_predictor import BloodPresurePredictor\n",
        "from utils import log_exp\n",
        "from utils import data_split\n",
        "\n",
        "def experiment(dataset, model, ntrees, N, key, target, log_path='', bootstrap=False, \n",
        "               bootstrap_size=0.8, aug='None'):\n",
        "    # Split dataset into train and test sets of features and labels\n",
        "    (x_train, y_train), (x_test, y_test) = data_split(dataset, y_columns=target, key_cols=key)\n",
        "    x_train = x_train.drop(key, axis=1)\n",
        "    x_test = x_test.drop(key, axis=1)\n",
        "\n",
        "    # First run with all features (either bootstrapped or not)\n",
        "    bp_predictor = BloodPresurePredictor(model, ntrees)\n",
        "    bp_predictor.fit(x_train, y_train, bootstrap, bootstrap_size)\n",
        "    # Evaluate the model\n",
        "    bp_predictor.evaluate(x_test, y_test)\n",
        "    \n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=False, bootstrap=bootstrap, test_size=x_test.shape)     \n",
        "    \n",
        "    # Second run with top N features\n",
        "    top_n = list(bp_predictor.feature_importances.keys())[:N]        # get top N features from dict \n",
        "    x_train = x_train[top_n]                                         # select top N features\n",
        "    bp_predictor.fit(x_train[top_n], y_train)                        # predict with top N features\n",
        "    bp_predictor.evaluate(x_test[top_n], y_test)                     # evaluate with top N features\n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=True, bootstrap=bootstrap, test_size=x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bp_predictor import BloodPresurePredictor\n",
        "from utils import log_exp, get_unique_healthCodes, average_dicts\n",
        "from collections import defaultdict\n",
        "\n",
        "def personalized_experiment(dataset, model, ntrees, N, key, target, log_path='', bootstrap=False, \n",
        "               bootstrap_size=0.8, aug='None', second_run=False, save_path=None):\n",
        "    \n",
        "    # Split dataset into train and test sets of features and labels\n",
        "    (x_train, y_train), (x_test, y_test) = data_split(dataset, y_columns=target, key_cols=key)\n",
        "    x_train_keys = x_train[key]\n",
        "    x_test_keys = x_test[key]\n",
        "    x_train = x_train.drop(key, axis=1)\n",
        "    x_test = x_test.drop(key, axis=1)\n",
        "\n",
        "    # First run with all features (either bootstrapped or not)\n",
        "    bp_predictor = BloodPresurePredictor(model, ntrees)\n",
        "    bp_predictor.fit(x_train, y_train, bootstrap, bootstrap_size)\n",
        "\n",
        "    # Get all unique healthCodes\n",
        "    all_users = get_unique_healthCodes(dataset)\n",
        "\n",
        "    # Initialize lists to store metrics results\n",
        "    mae = defaultdict(list)\n",
        "    mse = defaultdict(list)\n",
        "    temp_feature_importances = []\n",
        "    # Personalize the model for each user\n",
        "    for user in all_users:\n",
        "        tr_mask = x_train_keys.iloc[:, 0] == user\n",
        "        test_mask = x_test_keys.iloc[:, 0] == user\n",
        "        x_train_user, y_train_user = x_train[tr_mask], y_train[tr_mask]\n",
        "\n",
        "        x_test_user, y_test_user = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "        # Skips if there are no samples for the user\n",
        "        if x_train_user.shape[0] < 1 or x_test_user.shape[0] < 1:\n",
        "            continue\n",
        "\n",
        "        else:\n",
        "            bp_predictor.fine_tune(x_train_user, y_train_user)  # Fit the personalized model\n",
        "            bp_predictor.evaluate(x_test_user, y_test_user, fine_tuned=True)     # Evaluate the personalized model\n",
        "            # Performs second run with top N features if specified\n",
        "            if second_run:\n",
        "                top_n = list(bp_predictor.feature_importances.keys())[:N]\n",
        "                bp_predictor.fine_tune(x_train_user[top_n], y_train_user)\n",
        "                bp_predictor.evaluate(x_test_user[top_n], y_test_user, fine_tuned=True)\n",
        "            for bp_type in target:\n",
        "                mae[bp_type].append(bp_predictor.mae[bp_type])\n",
        "                mse[bp_type].append(bp_predictor.mse[bp_type])\n",
        "            temp_feature_importances.append(bp_predictor.feature_importances)\n",
        "\n",
        "            # Saves the model for the user\n",
        "            if save_path:\n",
        "                for bp_type in target:\n",
        "                    bp_predictor.ftmodel[bp_type].save_model(f'{save_path}/{user}_{bp_type}.json')\n",
        "\n",
        "    if len(mae) == 0:\n",
        "        print('No testing samples')\n",
        "        return\n",
        "    \n",
        "    # Average metrics for all users\n",
        "    for bp_type in target:\n",
        "        bp_predictor.mae[bp_type] = sum(mae[bp_type]) / len(mae[bp_type])\n",
        "        bp_predictor.mse[bp_type] = sum(mse[bp_type]) / len(mse[bp_type])\n",
        "    bp_predictor.feature_importances = average_dicts(temp_feature_importances)\n",
        "\n",
        "    # log results\n",
        "    log_exp(log_path, bp_predictor, aug=aug, N=N, second_run=second_run, bootstrap=bootstrap, \n",
        "            test_size=x_test.shape, personalized=True)\n",
        "   \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DygEtRF3rPGU"
      },
      "source": [
        "**Experiments with non-personalized model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASELINE - NO AUGMENTATION\n",
            "dataset size: (4, 11), model: xgb, ntrees: 60, sys_mae: 10.25,\n",
            "           dias_mae: 10.25, top_n: wo_calories; steps; distance_walking; bed_time; sleep_minutes, second run: False, bootstrap: True\n",
            "dataset size: (4, 11), model: xgb, ntrees: 60, sys_mae: 18.25,\n",
            "           dias_mae: 11.75, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "K-ROLL AUGMENTATION\n",
            "dataset size: (8, 11), model: xgb, ntrees: 60, sys_mae: 9.75,\n",
            "           dias_mae: 6.75, top_n: wo_calories; awake_count; sleep_minutes; distance_cycling; floors, second run: False, bootstrap: True\n",
            "dataset size: (8, 11), model: xgb, ntrees: 60, sys_mae: 8.5,\n",
            "           dias_mae: 7.625, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTRA AUGMENTATION\n",
            "dataset size: (31, 11), model: xgb, ntrees: 60, sys_mae: 9.968,\n",
            "           dias_mae: 9.548, top_n: awake_count; wo_calories; sleep_minutes; bed_time; active_calories, second run: False, bootstrap: True\n",
            "dataset size: (31, 11), model: xgb, ntrees: 60, sys_mae: 13.161,\n",
            "           dias_mae: 9.323, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n",
            "KNN INTER AUGMENTATION\n",
            "dataset size: (224, 11), model: xgb, ntrees: 60, sys_mae: 11.902,\n",
            "           dias_mae: 9.54, top_n: wo_calories; steps; bed_time; sleep_minutes; active_calories, second run: False, bootstrap: True\n",
            "dataset size: (224, 11), model: xgb, ntrees: 60, sys_mae: 11.33,\n",
            "           dias_mae: 9.638, top_n: N/A, second run: True, bootstrap: True\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "############################################# PARAMETERS #############################################\n",
        "N = 5                               # Number of most important features to display\n",
        "model = 'xgb'                       # rf or xgb (Random Forest or XGBoost)\n",
        "ntrees = 60                         # Number of trees in the forest\n",
        "double_run = False                  # Whether to use a second run with top N features or not\n",
        "bootstrap = True                    # Whether to use bootstrap samples\n",
        "bootstrap_size = 0.8                # Portion of the dataset to sample for bootstrap\n",
        "key = ['healthCode', 'date']        # Columns to use as key\n",
        "target = ['systolic', 'diastolic']  # Columns to predict\n",
        "log_path = 'exp_log.csv'            # Path of file to log experiment results\n",
        "\n",
        "\n",
        "############################################# EXPERIMENTS #############################################\n",
        "# Predicting systolic BP using baseline with non NaN values\n",
        "print('BASELINE - NO AUGMENTATION')\n",
        "dataset = baseline\n",
        "aug = 'None'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "# Predicting systolic BP using k-roll augmentation with non NaN values\n",
        "print('K-ROLL AUGMENTATION')\n",
        "dataset = augmented_k\n",
        "aug = 'K-roll'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting systolic BP using knn intra augmentation with non NaN values\n",
        "print('KNN INTRA AUGMENTATION')\n",
        "dataset = augmented_intra\n",
        "aug = 'KNN-intra'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting systolic BP using knn inter augmentation with non NaN values\n",
        "print('KNN INTER AUGMENTATION')\n",
        "dataset = augmented_inter\n",
        "aug = 'KNN-inter'\n",
        "experiment(dataset, model, ntrees, N, key, target, log_path=log_path, \n",
        "           bootstrap=bootstrap, bootstrap_size=bootstrap_size, aug=aug)\n",
        "print('--------------------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Experiments with personalized model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASELINE - NO AUGMENTATION\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'BloodPresurePredictor' object has no attribute 'save_model'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[46], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m aug \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m dataset \u001b[38;5;241m=\u001b[39m baseline\n\u001b[1;32m---> 18\u001b[0m \u001b[43mpersonalized_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbootstrap_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecond_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Predicting BP using k-roll augmentation with non NaN values\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[44], line 53\u001b[0m, in \u001b[0;36mpersonalized_experiment\u001b[1;34m(dataset, model, ntrees, N, key, target, log_path, bootstrap, bootstrap_size, aug, second_run, save_path)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# Saves the model for the user\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m bp_type \u001b[38;5;129;01min\u001b[39;00m target:\n\u001b[1;32m---> 53\u001b[0m             \u001b[43mbp_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbp_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mae) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo testing samples\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'BloodPresurePredictor' object has no attribute 'save_model'"
          ]
        }
      ],
      "source": [
        "############################################# PARAMETERS #############################################\n",
        "N = 5                               # Number of most important features to display\n",
        "ntrees = 60                         # Number of trees in the forest\n",
        "second_run = False                  # Whether to use a second run with top N features or not\n",
        "bootstrap = False                   # Whether to use bootstrap samples\n",
        "bootstrap_size = 0.8                # Portion of the dataset to sample for bootstrap\n",
        "key = ['healthCode', 'date']        # Columns to use as key\n",
        "target = ['systolic', 'diastolic']  # Columns to predict\n",
        "log_path = 'exp_log.csv'            # Path of file to log experiment results\n",
        "save_path = 'model_states'          # Path to save personalized models\n",
        "\n",
        "\n",
        "############################################# EXPERIMENTS #############################################\n",
        "# Predicting BP using baseline with non NaN values\n",
        "print('BASELINE - NO AUGMENTATION')\n",
        "aug = 'None'\n",
        "dataset = baseline\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "# Predicting BP using k-roll augmentation with non NaN values\n",
        "print('K-ROLL AUGMENTATION')\n",
        "dataset = augmented_k\n",
        "aug = 'K-roll'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting BP using knn intra augmentation with non NaN values\n",
        "print('KNN INTRA AUGMENTATION')\n",
        "dataset = augmented_intra\n",
        "aug = 'KNN-intra'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Predicting BP using knn inter augmentation with non NaN values\n",
        "print('KNN INTER AUGMENTATION')\n",
        "dataset = augmented_inter\n",
        "aug = 'KNN-inter'\n",
        "personalized_experiment(dataset, 'xgb', ntrees, N, key, target, log_path=log_path, bootstrap=bootstrap, \n",
        "                        bootstrap_size=bootstrap_size, aug=aug, second_run=second_run, save_path=save_path)\n",
        "print('--------------------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def historical_BP(predictor, k):\n",
        "    data = predictor.copy()\n",
        "    #Sorting the data by healthCode and date\n",
        "    predictor.sort_values(by=['healthCode', 'date'], inplace=True)\n",
        "\n",
        "    for col in ['systolic', 'diastolic']:\n",
        "        data[col+'_'+str(k)] = predictor.groupby('healthCode')[col].transform(lambda x: x.rolling(window=k, min_periods=1).mean())\n",
        "\n",
        "    return historical_BP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ADD HISTORICAL BP\n",
        "\n",
        "\n",
        "# from augmentations import historical_BP\n",
        "\n",
        "historical = historical_BP(baseline, 3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
