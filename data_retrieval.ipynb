{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEGAEuRb_-r9"
      },
      "source": [
        "##Important library install and connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrTqf6f17W-u",
        "outputId": "392df8d2-2cc9-4295-a240-9c8d8a1c790c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome, Humphrey Kanyoke!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import synapseclient\n",
        "\n",
        "syn = synapseclient.Synapse()\n",
        "with open('token.txt', 'r') as file:\n",
        "  token = file.readline().strip()\n",
        "syn.login(authToken=token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdrBFIkDJj3E"
      },
      "source": [
        "##Dataset with their access codes\n",
        "List of tables available in the database. Those which are of our use is marked as (o) and those which are not of our use is marked as (x). Table which might be required for discussion or for extension purpose are marked as (~)\n",
        "\n",
        "|Table name         | Access code  | Note | Time Series | # Patients| Avg # entries per patient| Median  # entries per patient |\n",
        "|-------------------|--------------|------|-------------|-----------|-------|-------|\n",
        "|Day One Survey **(x)**      |syn16782072   |\n",
        "|PAR-Q Survey **(x)**       | syn16782071  |\n",
        "|Daily Check Survey **(o)** |syn16782070   | | Y | 17622 | 7.74 | 4.0 |\n",
        "|Activity and Sleep Survey **(~)** | syn16782069| for discussion purpose | ? | 23232 | 1.07 | 1.0 |\n",
        "|Risk Factor Survey **(o)** |syn16782068   | | ? | 13851 | 1.03 | 1.0 |\n",
        "|Cardio Diet Survey **(x)** | syn16782067  |\n",
        "|Satisfied Survey   **(x)**| syn16782066 |\n",
        "|**APH Heart Age Survey (o)**|**syn16782065** | **Contains BP data** | Y | 4759 | 2.26 | 1.0 |\n",
        "|Six Minute Walk Activity **(o)**| syn16782064 | | Y | 3441 | 1.98 | 1.0 |\n",
        "|Demographics Survey **(o)** | syn16782063 | Contains wakeup, sleep time| Y | 7565 | 1.64 | 1.0 |\n",
        "|HealthKit Data **(o)**| syn16782062 | Distance walked/run data from smart device | Y | 4920 | 23.77 | 5.0 |\n",
        "|HealthKit Sleep **(o)**| syn16782061 | Sleep data from smart device| Y | 626 | 4.22 | 2.0 |\n",
        "|HealthKit Workout **(o)** | syn16782060 | Workout data (mostly walking) from smart device| Y | 881 | 3.71 | 1.0 |\n",
        "|Motion Tracker **(x)**| syn16782059 | Its a tmp file\n",
        "|Six Minute Walk - Displacement Vectors **(x)**| syn16782058| Unknown file type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xiTvKbkvIJF"
      },
      "source": [
        "##Data Access and pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvemE88G8fi8",
        "outputId": "3319e91c-7a98-4e99-9b9c-8809b4368c1c"
      },
      "outputs": [],
      "source": [
        "query = syn.tableQuery(\"SELECT * FROM  \tsyn16782061\")\n",
        "raw_df = query.asDataFrame()\n",
        "print(raw_df)\n",
        "\n",
        "# Specify the columns to download\n",
        "cols_to_download = ['data.csv']\n",
        "\n",
        "# Download the CSV file\n",
        "downloaded_files = syn.downloadTableColumns(query, cols_to_download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3ZTjsFmRuAv"
      },
      "source": [
        "**Clean Sleep data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ok1eH4BeOQ1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_sleep_record(raw_df, index):\n",
        "  # Get the file handle ID of the CSV file\n",
        "  file_handle_id = raw_df.iloc[index]['data.csv']\n",
        "\n",
        "  # Get the path of the file in the cache\n",
        "  file_path = syn.cache.get(file_handle_id)\n",
        "\n",
        "  try:\n",
        "    # Load the CSV file into a pandas DataFrame and group by day (summming)\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[df['category.value']=='HKCategoryValueSleepAnalysisAsleep']\n",
        "    df['startTime'] = pd.to_datetime(df['startTime'])\n",
        "    df['value'] = df['value'] / 60    # Convert from seconds to minutes\n",
        "    df['date'] = df['startTime'].dt.date\n",
        "    df['bed_time'] = df['startTime'].dt.time\n",
        "    df = df.drop_duplicates(subset=['startTime', 'value'])    # Remove duplicate sleep entries\n",
        "    # Group by 'date', calculate sum of 'value', count the number of rows per group, and get the date of the row with the highest 'value'\n",
        "    clean_df = df.groupby('date').agg({'value': ['sum', 'count', lambda x: df.loc[x.idxmax(), 'bed_time']]}).reset_index()\n",
        "\n",
        "\n",
        "\n",
        "    clean_df.columns = ['date', 'sleep_minutes', 'awake_count', 'bed_time']\n",
        "\n",
        "    return clean_df\n",
        "\n",
        "  except:\n",
        "    ('Bad date entry')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wURcv9QMwF-g"
      },
      "source": [
        "**Create Master sleep dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYi4lFqlmwbB",
        "outputId": "21fed212-9767-44da-9e19-26c85c528188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2644/2644 [00:23<00:00, 114.74it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Create empty df to which entries in the form of (healthCode, Date, value) will be entered\n",
        "sleep = pd.DataFrame(columns=['healthCode', 'date', 'sleep_minutes', 'awake_count', 'bed_time'])\n",
        "\n",
        "# For every clean set of sleep entries, add all the (Date, value) tuples to its corresponding \n",
        "# healthCode to create the entry to add to the main results dataframe\n",
        "for i in tqdm(range(raw_df.shape[0])):\n",
        "  sleep_entries = clean_sleep_record(raw_df, i)\n",
        "  if sleep_entries is not None:\n",
        "    sleep_entries['healthCode'] = raw_df.iloc[i]['healthCode']\n",
        "    sleep = pd.concat([sleep, sleep_entries], ignore_index=True)\n",
        "\n",
        "# Adds waking minutes and removes entries with more than 18 hours of sleep\n",
        "sleep.loc['awake_minutes'] = (24 * 60) - sleep['sleep_minutes']\n",
        "sleep = sleep[sleep['sleep_minutes'] < (18 * 60)]\n",
        "sleep.to_csv('sleep.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ei4fcxBx3F"
      },
      "outputs": [],
      "source": [
        "print(sleep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHBsE2CwTyf"
      },
      "source": [
        "**Merge BP and Sleep Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAPX5mL7wYCy"
      },
      "outputs": [],
      "source": [
        "query = syn.tableQuery(\"SELECT * FROM   syn16782065\")\n",
        "bp = query.asDataFrame()\n",
        "bp['createdOn'] = bp['createdOn'] / 1000\n",
        "bp['createdOn'] = pd.to_datetime(bp['createdOn'], unit='s')\n",
        "bp['date'] = bp['createdOn'].dt.date\n",
        "\n",
        "bp = bp.merge(sleep, on=['healthCode', 'date'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxdnQZifyZNf",
        "outputId": "2f1a6e06-a519-474e-c5c7-ca96ed6efd14"
      },
      "outputs": [],
      "source": [
        "print(bp[bp['sleep'].notna()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvVtrgjQXZTT"
      },
      "source": [
        "###**Data Download and Pre-processing of HealthKit Data (Activity Data)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oic5HrxmbvWQ"
      },
      "source": [
        "**Setting up Config for download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3QXmMNZb0kq",
        "outputId": "c8821085-2188-4805-f1a3-dbfdf0d535ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome, Humphrey Kanyoke!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import synapseclient\n",
        "syn = synapseclient.Synapse()\n",
        "syn.cache.cache_root_dir = 'raw_data'    # Change cache path\n",
        "with open('token.txt', 'r') as file: # fran_token.txt would work just fine\n",
        "  token = file.readline().strip()\n",
        "syn.login(authToken=token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOQ0XgnncV4Z"
      },
      "source": [
        "**Downloading all individual .csv file**\\\n",
        "*!! Download of 3.62 GBs of data, may take 90 minutes or more*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q9cCbF2nblXn"
      },
      "outputs": [],
      "source": [
        "## Querying the HealthKit Data table\n",
        "\n",
        "query0 = syn.tableQuery(\"select healthCode from syn16782065\")\n",
        "patients_list_df = query0.asDataFrame()\n",
        "patients_list = patients_list_df['healthCode'].astype(str).to_list()\n",
        "patients = ','.join(f\"'{x}'\" for x in patients_list)\n",
        "\n",
        "query1 = \"select * from syn16782062 where healthCode in (\"+ patients + \")\"\n",
        "query1 = syn.tableQuery(query1)\n",
        "raw_df_dat = query1.asDataFrame()\n",
        "\n",
        "# # Specify the columns to download\n",
        "# cols_to_download = ['data.csv']\n",
        "\n",
        "# # Download the CSV file\n",
        "# syn.downloadTableColumns(query1, cols_to_download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCfRPyQemQe0"
      },
      "source": [
        "**Creating Master activities dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Zox21yO4mYni"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_hk_records(raw_df_dat, index):\n",
        "  '''\n",
        "  Extracts the HealthKit records from the synapse database and returns a DataFrame containing\n",
        "  all records for all patients\n",
        "  '''\n",
        "  file_handle_id = raw_df_dat.iloc[index]['data.csv']\n",
        "  file_path = syn.cache.get(file_handle_id)\n",
        "\n",
        "  df_dat = pd.read_csv(file_path)\n",
        "\n",
        "  # Date formating\n",
        "  date_format = \"%Y-%m-%dT%H:%M:%S%z\"  # ISO 8601 date format with timezone\n",
        "  df_dat['startTime'] = pd.to_datetime(df_dat['startTime'], format=date_format, errors='coerce', utc=True )\n",
        "  # Convert datetime objects to Timestamp objects and remove timezone information\n",
        "  df_dat['startTime'] = df_dat['startTime'].apply(lambda x: pd.Timestamp(x).tz_localize(None) if pd.notnull(x) else pd.NaT)\n",
        "  df_dat['date'] = df_dat['startTime'].dt.date\n",
        "\n",
        "  return df_dat\n",
        "\n",
        "\n",
        "def clean_hk_records(df_dat, activities_for_sum, activities_for_avg):\n",
        "  '''\n",
        "  Cleans the HealthKit records by transposing the 'type' column into separate columns and\n",
        "  aggregating the records to a daily rate\n",
        "  '''\n",
        "  print('number of total entries:', df_dat.shape[0])\n",
        "  # Filter out the records that are not in the list of activities to sum or average\n",
        "  df_dat = df_dat[df_dat['type'].isin(activities_for_sum+activities_for_avg)].copy()\n",
        "  print('filtered columns', df_dat['type'].unique())\n",
        "  print('number of filtered entries:', df_dat.shape[0])\n",
        "  print('unique healthCode & date entries:', df_dat.groupby(['healthCode', 'date']).ngroups)\n",
        "  print('unique healthCode, date, & type entries:', df_dat.groupby(['healthCode', 'date', 'type']).ngroups)\n",
        "  # Ensure that the 'value' column contains only numeric values\n",
        "  df_dat['value'] = pd.to_numeric(df_dat['value'], errors='coerce').fillna(0)\n",
        "\n",
        "  # Pivot the DataFrame so that each unique value in 'type' becomes a new column\n",
        "  df_dat.reset_index(inplace=True)\n",
        "  df_dat.rename(columns={'index': 'temp_index'}, inplace=True)\n",
        "  df_dat = df_dat.pivot_table(index=['temp_index', 'healthCode', 'date'], \n",
        "                              columns='type', values='value').reset_index()\n",
        "  df_dat = df_dat.fillna(0)\n",
        "  print('pivoted shape', df_dat.shape)\n",
        "  print('pivoted columns', df_dat.columns)\n",
        "  print('total non-zero entries after pivoting:', df_dat.iloc[:, 3:].astype(bool).sum().sum())\n",
        "  \n",
        "  # Group by 'date', sum for activities_for_sum, average for activities_for_avg\n",
        "  activities_for_sum = list(set(activities_for_sum) & set(df_dat.columns))\n",
        "  activities_for_avg = list(set(activities_for_avg) & set(df_dat.columns))\n",
        "  agg_dict = {activity: 'sum' for activity in activities_for_sum}\n",
        "  agg_dict.update({activity: 'mean' for activity in activities_for_avg})\n",
        "  clean_df = df_dat.groupby(['healthCode', 'date']).agg(agg_dict).reset_index()\n",
        "  clean_df = clean_df.fillna(0)\n",
        "\n",
        "  return clean_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\frana\\AppData\\Local\\Temp\\ipykernel_10424\\2638161674.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  raw_hk = pd.read_csv('data/raw_hk.csv')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             healthCode        date            startTime  \\\n",
            "0  12a38046-1512-409a-b3a1-6046e97e650e  2015-06-21  2015-06-21 18:58:49   \n",
            "1  12a38046-1512-409a-b3a1-6046e97e650e  2015-06-21  2015-06-21 19:22:11   \n",
            "2  12a38046-1512-409a-b3a1-6046e97e650e  2015-06-21  2015-06-21 19:28:11   \n",
            "3  12a38046-1512-409a-b3a1-6046e97e650e  2015-06-21  2015-06-21 23:22:37   \n",
            "4  12a38046-1512-409a-b3a1-6046e97e650e  2015-06-21  2015-06-21 23:28:37   \n",
            "\n",
            "                     endTime                                            type  \\\n",
            "0  2015-06-21T13:58:51-05:00  HKQuantityTypeIdentifierDistanceWalkingRunning   \n",
            "1  2015-06-21T14:28:11-05:00  HKQuantityTypeIdentifierDistanceWalkingRunning   \n",
            "2  2015-06-21T14:28:14-05:00  HKQuantityTypeIdentifierDistanceWalkingRunning   \n",
            "3  2015-06-21T18:28:37-05:00  HKQuantityTypeIdentifierDistanceWalkingRunning   \n",
            "4  2015-06-21T18:30:27-05:00  HKQuantityTypeIdentifierDistanceWalkingRunning   \n",
            "\n",
            "     value unit source  sourceIdentifier  \n",
            "0  1.63892    m  phone  com.apple.health  \n",
            "1  1.63892    m  phone  com.apple.health  \n",
            "2  6.93442    m  phone  com.apple.health  \n",
            "3  6.93442    m  phone  com.apple.health  \n",
            "4  51.5103    m  phone  com.apple.health  \n",
            "(18768522, 9)\n"
          ]
        }
      ],
      "source": [
        "raw_hk = pd.read_csv('data/raw_hk.csv')\n",
        "print(raw_hk.head())\n",
        "print(raw_hk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "___________________________________________________________________\n",
            "number of total entries: 18768522\n",
            "filtered columns ['HKQuantityTypeIdentifierDistanceWalkingRunning'\n",
            " 'HKQuantityTypeIdentifierStepCount'\n",
            " 'HKQuantityTypeIdentifierFlightsClimbed'\n",
            " 'HKQuantityTypeIdentifierHeartRate'\n",
            " 'HKQuantityTypeIdentifierDistanceCycling'\n",
            " 'HKQuantityTypeIdentifierBloodPressureSystolic'\n",
            " 'HKQuantityTypeIdentifierBloodPressureDiastolic'\n",
            " 'HKQuantityTypeIdentifierActiveEnergyBurned']\n",
            "number of filtered entries: 18613281\n",
            "unique healthCode & date entries: 51123\n",
            "unique healthCode, date, & type entries: 127223\n",
            "pivoted shape (18613223, 11)\n",
            "pivoted columns Index(['temp_index', 'healthCode', 'date',\n",
            "       'HKQuantityTypeIdentifierActiveEnergyBurned',\n",
            "       'HKQuantityTypeIdentifierBloodPressureDiastolic',\n",
            "       'HKQuantityTypeIdentifierBloodPressureSystolic',\n",
            "       'HKQuantityTypeIdentifierDistanceCycling',\n",
            "       'HKQuantityTypeIdentifierDistanceWalkingRunning',\n",
            "       'HKQuantityTypeIdentifierFlightsClimbed',\n",
            "       'HKQuantityTypeIdentifierHeartRate',\n",
            "       'HKQuantityTypeIdentifierStepCount'],\n",
            "      dtype='object', name='type')\n",
            "total non-zero entries after pivoting: 18319670\n",
            "total non-zero entries after aggregating: type\n",
            "HKQuantityTypeIdentifierDistanceWalkingRunning    34248\n",
            "HKQuantityTypeIdentifierFlightsClimbed            24785\n",
            "HKQuantityTypeIdentifierActiveEnergyBurned        11455\n",
            "HKQuantityTypeIdentifierStepCount                 37906\n",
            "HKQuantityTypeIdentifierBloodPressureSystolic      1758\n",
            "HKQuantityTypeIdentifierHeartRate                 13781\n",
            "HKQuantityTypeIdentifierBloodPressureDiastolic     1802\n",
            "dtype: int64\n",
            "number of rows in hk 51123\n",
            "rows with at least 1 non-zero entry 50825\n",
            "total non-zero entries after aggregating: 125735\n"
          ]
        }
      ],
      "source": [
        "# Subsample hk for practicality during debugging\n",
        "sub_raw_hk = raw_hk.iloc[:, :-3]\n",
        "print('___________________________________________________________________')\n",
        "\n",
        "activities_for_sum = ['HKQuantityTypeIdentifierFlightsClimbed', 'HKQuantityTypeIdentifierDistanceWalkingRunning', \n",
        "                      'HKQuantityTypeIdentifierStepCount', 'HKQuantityTypeIdentifierDistanceCycling', \n",
        "                      'HKQuantityTypeIdentifierActiveEnergyBurned']\n",
        "activities_for_avg = ['HKQuantityTypeIdentifierHeartRate', 'HKQuantityTypeIdentifierBloodPressureDiastolic', \n",
        "                      'HKQuantityTypeIdentifierBloodPressureSystolic']\n",
        "\n",
        "hk = clean_hk_records(sub_raw_hk, activities_for_sum, activities_for_avg)\n",
        "# print number of rows with all 0 values for all columns except for date and healthCode\n",
        "print('total non-zero entries after aggregating:', hk.iloc[:, 3:].astype(bool).sum())\n",
        "print('number of rows in hk', hk.shape[0])\n",
        "print('rows with at least 1 non-zero entry', hk.iloc[:, 3:].ne(0).any(axis=1).sum())\n",
        "print('total non-zero entries after aggregating:', hk.iloc[:, 3:].astype(bool).sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "hk.to_csv('data/healthkit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hk = pd.DataFrame(columns=['healthCode', 'date'])\n",
        "for i in tqdm(range(raw_df_dat.shape[0])):\n",
        "  hk_entries = extract_hk_records(raw_df_dat, i)\n",
        "  if hk_entries is not None:\n",
        "    hk_entries['healthCode'] = raw_df_dat.iloc[i]['healthCode']\n",
        "    hk = pd.concat([hk, hk_entries], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYP-JNwBc3vH"
      },
      "source": [
        "**Merging BP and activities data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc-N_DTsc7Ny"
      },
      "outputs": [],
      "source": [
        "query = syn.tableQuery(\"SELECT * FROM   syn16782065\")\n",
        "bp = query.asDataFrame()\n",
        "bp['createdOn'] = bp['createdOn'] / 1000\n",
        "bp['createdOn'] = pd.to_datetime(bp['createdOn'], unit='s')\n",
        "bp['date'] = bp['createdOn'].dt.date\n",
        "\n",
        "bp_activities = bp.merge(df_activities, on=['healthCode', 'date'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "M_mot_nudCTM",
        "outputId": "5df2cf46-06f5-4ead-92e4-e1102500cfd7"
      },
      "outputs": [],
      "source": [
        "bp_activities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK5ZFdvqgJLc"
      },
      "source": [
        "###**Data Download and Pre-processing of HealthKit Workout**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hq-_GUEgUUE"
      },
      "source": [
        "**Setting up config for download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLp2_E31gTzK"
      },
      "outputs": [],
      "source": [
        "syn.cache.cache_root_dir = '/content/workout_data'    # Change cache path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWOjVO0Egzvn"
      },
      "source": [
        "**Downloading all individual .csv file**\n",
        "*Took 3m 21s to download the data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNgmsfzdB30",
        "outputId": "3f50d3f4-194d-4958-d1be-dc1faf5cf0d9"
      },
      "outputs": [],
      "source": [
        "query_wo = syn.tableQuery(\"select healthCode from syn16782065\")\n",
        "patients_list_df = query_wo.asDataFrame()\n",
        "patients_list = patients_list_df['healthCode'].astype(str).to_list()\n",
        "patients = ','.join(f\"'{x}'\" for x in patients_list)\n",
        "\n",
        "query_wo = \"select * from syn16782060 where healthCode in (\"+ patients + \")\"\n",
        "query_wo = syn.tableQuery(query_wo)\n",
        "raw_df_wo = query_wo.asDataFrame()\n",
        "\n",
        "# Specify the columns to download\n",
        "cols_to_download = ['data.csv']\n",
        "\n",
        "# Download the CSV file\n",
        "syn.downloadTableColumns(query_wo, cols_to_download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3EjMS24iiMa"
      },
      "source": [
        "**Creating workout dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgnX4tFOik6p",
        "outputId": "77c97ab7-d728-4705-ab36-7bb796f9d024"
      },
      "outputs": [],
      "source": [
        "bad_records_wo = []\n",
        "def clean_data_records(raw_df_wo, index):\n",
        "    file_handle_id = raw_df_wo.iloc[index]['data.csv']\n",
        "    file_path = syn.cache.get(file_handle_id)\n",
        "\n",
        "    try:\n",
        "      df_dat = pd.read_csv(file_path)\n",
        "      df_dat['startTime'] = pd.to_datetime(df_dat['startTime'])\n",
        "      df_dat['endTime'] = pd.to_datetime(df_dat['endTime'])\n",
        "\n",
        "      df_dat = df_dat[df_dat['workoutType'].str.contains('HKWorkoutActivityType')] # deleting rows which contains junt activity type\n",
        "      df_dat = df_dat.drop(['type', 'total.distance', 'unit', 'source', 'sourceIdentifier', 'metadata'], axis=1) # Dropping unnecessary columns\n",
        "      df_dat = df_dat.drop_duplicates(subset=['startTime', 'endTime']) # removing redundant rows\n",
        "      #df_dat_sum = df_dat.groupby('date')['energy.consumed'].sum().reset_index()\n",
        "      df_dat = df_dat[pd.to_numeric(df_dat['energy.consumed'], errors='coerce').notnull()] # deleting values having non-numeric energy.consumed value\n",
        "      return df_dat\n",
        "\n",
        "    except:\n",
        "        bad_records_wo.append(raw_df_wo.iloc[index]['recordId'])\n",
        "\n",
        "df_workout = pd.DataFrame()\n",
        "\n",
        "# For every clean set of sleep entries, add all the (Date, value) tuples to its corresponding healthCode to create the entry to add to the main results dataframe\n",
        "for i in range(raw_df_wo.shape[0]):\n",
        "#for i in range(209): #To run a subset\n",
        "    data_entries = clean_data_records(raw_df_wo, i)\n",
        "    #print(data_entries)\n",
        "    if data_entries is not None:\n",
        "        data_entries['healthCode'] = raw_df_wo.iloc[i]['healthCode']\n",
        "        df_workout = pd.concat([df_workout, data_entries], ignore_index=True)\n",
        "        print(i, \" of \", raw_df_wo.shape[0], \" processed\")\n",
        "\n",
        "df_workout.to_csv('workout.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPMfR3jaTvWs"
      },
      "source": [
        "Add rolling K averaging to populate missing values in dataframe"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
